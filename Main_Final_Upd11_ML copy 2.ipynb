{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок с оптимизацией по историческим данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Единый конфиг (словарь)\n",
    "\n",
    "config = {\n",
    "    \"model\": \"XGBRegressor\", # модель (Prophet или XGBRegressor)\n",
    "    \"tickers\": [\"SBER\", \"GAZP\", \"LKOH\", \"NVTK\", \"MGNT\", \"TATN\", \"ROSN\", \"RUAL\", \"T\", \"MOEX\", \"YDEX\", \"HHRU\"], # тикеры \"AAPL\", \"MSFT\", \"NVDA\", \"AMZN\", \"TSLA\", \"MA\" / \"SBER\", \"GAZP\", \"LKOH\", \"NVTK\", \"MGNT\", \"TATN\"\n",
    "    \"bond_tickers\": [],  # номера облигаций \"SU29020RMFS3\", \"RU000A1094F2\"\n",
    "    \"start_date\": \"2023-01-01\",           # дата начала истории\n",
    "    \"end_date\": \"2025-05-12\",             # дата конца истории\n",
    "    \"source\": \"moex\",                     # выбор источника истории (moex или yfinance)\n",
    "    \"risk_free_rate\": 0.15                # безрисковая ставка (15% для РФ / 5% для US)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Универсальный загрузчик акций и облигаций\n",
    "def get_price_data(tickers, start, end, source=\"yfinance\", bond_tickers=None):\n",
    "    if source == \"yfinance\": \n",
    "        price_df = get_data_yfinance(tickers, start, end)\n",
    "    elif source == \"moex\":\n",
    "        price_df = get_data_moex(tickers, start, end)\n",
    "        \n",
    "        # Если переданы облигации — загружаем и объединяем\n",
    "        if bond_tickers:\n",
    "            bond_df = get_bond_data_moex(bond_tickers, start, end)\n",
    "            price_df = pd.concat([price_df, bond_df], axis=1).sort_index()\n",
    "    else:\n",
    "        raise ValueError(\"Источник должен быть 'yfinance' или 'moex'\")\n",
    "    \n",
    "    return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем данные из функции выше\n",
    "price_data = get_price_data(\n",
    "    config[\"tickers\"],\n",
    "    config[\"start_date\"],\n",
    "    config[\"end_date\"],\n",
    "    config[\"source\"],\n",
    "    bond_tickers=config.get(\"bond_tickers\")\n",
    ")\n",
    "\n",
    "# Проверка и очистка\n",
    "if price_data.empty:\n",
    "    raise ValueError(\"Ошибка: данные не загружены. Проверьте тикеры и даты.\")\n",
    "\n",
    "# Заполняем пропуски методом прямой подстановки\n",
    "price_data = price_data.fillna(method=\"ffill\").fillna(method=\"bfill\") # заполнение пустоты предыдущим значением, оставшиеся пропуски просто удаляются\n",
    "\n",
    "# Визуализация нормализованных цен\n",
    "(price_data / price_data.iloc[0]).plot(figsize=(12, 6), title=\"Нормализованные цены акций\", logy=True) # деление нужно чтобы все акции начинались с 1\n",
    "plt.xlabel(\"Дата\")\n",
    "plt.ylabel(\"Относительная цена\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Логарифмическая доходность\n",
    "log_returns = np.log(price_data / price_data.shift(1)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим корреляционную матрицу доходностей\n",
    "correlation_matrix = log_returns.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Назначение весов по годам ===\n",
    "\n",
    "# Настраиваемый словарь весов по годам\n",
    "year_weights = {\n",
    "    2021: 0.4,\n",
    "    2022: 0.2,\n",
    "    2023: 0.8,\n",
    "    2024: 1.0,\n",
    "}\n",
    "\n",
    "# Функция для получения веса для каждой даты\n",
    "def get_weights_for_dates(dates, year_weights_dict, default_weight=1.0):\n",
    "    years = dates.year  # тут dates — это сразу DatetimeIndex\n",
    "    weights = pd.Series([year_weights_dict.get(y, default_weight) for y in years], index=dates)\n",
    "    return weights\n",
    "\n",
    "# Применяем веса к логарифмическим доходностям\n",
    "weights_series = get_weights_for_dates(log_returns.index, year_weights)\n",
    "\n",
    "# Сохраняем в отдельную переменную на будущее\n",
    "log_returns_weights = weights_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Получим список тикеров из конфига\n",
    "tickers = config['tickers'] + config['bond_tickers']\n",
    "\n",
    "# 2. Оставим только нужные активы в log_returns\n",
    "log_returns_subset = log_returns[tickers]\n",
    "\n",
    "# 3. Создадим бенчмарк — среднюю доходность портфеля\n",
    "benchmark_returns = log_returns_subset.mean(axis=1)\n",
    "\n",
    "# 4. Расчёт бета-коэффициентов\n",
    "def compute_beta(returns_df, benchmark_returns):\n",
    "    betas = {}\n",
    "    for ticker in returns_df.columns:\n",
    "        model = LinearRegression()\n",
    "        model.fit(benchmark_returns.values.reshape(-1, 1), returns_df[ticker].values)\n",
    "        betas[ticker] = model.coef_[0]  # это и есть β\n",
    "    return pd.Series(betas)\n",
    "\n",
    "betas_series = compute_beta(log_returns_subset, benchmark_returns)\n",
    "\n",
    "# 5. Преобразуем в словарь для маппинга в ML\n",
    "betas_dict = betas_series.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Взвешенная средняя доходность ===\n",
    "mean_daily_returns = (log_returns.mul(log_returns_weights, axis=0)).sum() / log_returns_weights.sum()\n",
    "\n",
    "# === Взвешенная ковариационная матрица ===\n",
    "# Центрируем данные\n",
    "centered_returns = log_returns - mean_daily_returns\n",
    "\n",
    "# Применяем веса\n",
    "weighted_centered = centered_returns.mul(np.sqrt(log_returns_weights), axis=0)\n",
    "\n",
    "# Взвешенная ковариация\n",
    "cov_matrix = (weighted_centered.T @ weighted_centered) / log_returns_weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Кол-во активов\n",
    "num_assets = len(config[\"tickers\"] + config[\"bond_tickers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Целевая функция — отрицательный коэффициент Шарпа\n",
    "def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate): # основные параметры для функции минимизации\n",
    "    port_return = np.dot(weights, mean_returns) # ожидаемая средняя доходность портфеля\n",
    "    port_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights))) # стандартное отклонение доходности\n",
    "    sharpe_ratio = (port_return - risk_free_rate / 252) / port_volatility # расчет коээфа Шарпа (деление на 252 нужно чтобы получить дневной процент)\n",
    "    return -sharpe_ratio # отицательный коэфф Шарпа для максимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ограничения и условия\n",
    "constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # сумма весов = 1\n",
    "bounds = tuple((0, 1) for _ in range(num_assets))  # веса от 0 до 1\n",
    "initial_guess = num_assets * [1. / num_assets]  # равные веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизация\n",
    "opt_result = minimize(\n",
    "    neg_sharpe_ratio, # отрицательный коэфф Шарпа\n",
    "    initial_guess, # равные веса активов\n",
    "    args=(mean_daily_returns, cov_matrix, config[\"risk_free_rate\"]), # аргументы для целевой функции где мы отрицательный коэф Шарпа искали\n",
    "    method=\"SLSQP\", # метод минимизации \n",
    "    bounds=bounds, # ограничения по весам активов\n",
    "    constraints=constraints # ограничение по сумме весов\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимальные веса\n",
    "optimal_weights = opt_result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимальная дневная доходность и риск\n",
    "port_return_daily = np.dot(optimal_weights, mean_daily_returns)\n",
    "port_volatility_daily = np.sqrt(np.dot(optimal_weights.T, np.dot(cov_matrix, optimal_weights)))\n",
    "\n",
    "# Годовые метрики\n",
    "port_return_annual = port_return_daily * 252\n",
    "port_volatility_annual = port_volatility_daily * np.sqrt(252)\n",
    "\n",
    "# Шарп\n",
    "sharpe_ratio_annual = (port_return_annual - config[\"risk_free_rate\"]) / port_volatility_annual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Печатаем метрики\n",
    "print(\"Оптимальные веса в портфеле:\")\n",
    "for ticker, weight in zip(tickers, optimal_weights):\n",
    "    print(f\"{ticker}: {weight:.2%}\")\n",
    "\n",
    "print(f\"\\nДоходность портфеля: {port_return_daily:.4f} в день, {port_return_annual:.2%} в год\")\n",
    "print(f\"Риск портфеля (волатильность): {port_volatility_daily:.4f} в день, {port_volatility_annual:.2%} в год\")\n",
    "print(f\"Коэффициент Шарпа (годовой): {sharpe_ratio_annual:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исключаем активы с нулевым весом\n",
    "non_zero_weights = [(ticker, weight) for ticker, weight in zip(tickers, optimal_weights) if weight > 1e-6]  # Убираем веса, близкие к нулю\n",
    "\n",
    "# Проверяем, есть ли активы с ненулевыми весами\n",
    "if non_zero_weights:\n",
    "    # Разделяем тикеры и веса\n",
    "    filtered_tickers, filtered_weights = zip(*non_zero_weights)\n",
    "\n",
    "    # Построение диаграммы\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(filtered_weights, labels=filtered_tickers, autopct=\"%1.1f%%\", startangle=140)\n",
    "    plt.title(\"Оптимальное распределение активов\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Все активы имеют нулевые веса. Нечего отображать.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доходность портфеля с равными и оптимальными весами\n",
    "equal_weights = np.repeat(1/num_assets, num_assets)\n",
    "\n",
    "# Капитал под управлением\n",
    "initial_capital = 100\n",
    "\n",
    "# Кумулятивная доходность\n",
    "portfolio_equal = (log_returns @ equal_weights).cumsum()\n",
    "portfolio_optimal = (log_returns @ optimal_weights).cumsum()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(portfolio_equal, label=\"Равные веса\", linestyle=\"--\")\n",
    "plt.plot(portfolio_optimal, label=\"Оптимальный портфель\", linewidth=2)\n",
    "plt.title(\"Кумулятивная доходность портфеля\")\n",
    "plt.ylabel(\"Суммарная лог-доходность\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок с прогнозом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_lags = 30  # Количество лагов (дней), используемых для построения признаков\n",
    "horizon = 30  # Горизонт прогнозирования (количество дней вперед)\n",
    "expected_returns_ml = {}  # Словарь для хранения ожидаемых доходностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {} # Словарь для хранения прогнозных цен\n",
    "\n",
    "if config[\"model\"] == \"XGBRegressor\":\n",
    "    for ticker in price_data.columns:\n",
    "        # Подготовка данных\n",
    "        df = price_data[ticker].copy().reset_index()  # Преобразуем индекс в столбец\n",
    "        df = df.rename(columns={\"index\": \"Date\"})  # Убедимся, что столбец называется \"Date\"\n",
    "\n",
    "        # Создаем лаги\n",
    "        for lag in range(1, n_lags + 1):\n",
    "            df[f\"lag_{lag}\"] = df[ticker].shift(lag)\n",
    "\n",
    "        # Целевая переменная — цена на следующий день\n",
    "        df[\"target\"] = df[ticker].shift(-1)\n",
    "        df_model = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        # Проверяем, достаточно ли данных для обучения\n",
    "        if len(df_model) < 100:\n",
    "            print(f\"Недостаточно данных для {ticker}, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        # Сохраняем оригинальные индексы\n",
    "        original_indices = df_model[\"Date\"]\n",
    "\n",
    "        # Разделяем данные на признаки и целевую переменную\n",
    "        X = df_model[[f\"lag_{i}\" for i in range(1, n_lags + 1)]].copy()\n",
    "        y = df_model[\"target\"]\n",
    "\n",
    "        # Разделяем данные на обучающую и тестовую выборки\n",
    "        X_train, X_test, y_train, y_test, indices_train, indices_test = train_test_split(\n",
    "            X, y, original_indices, shuffle=False, test_size=0.2\n",
    "        )\n",
    "\n",
    "        # Отбор весов по оригинальным индексам\n",
    "        weights_train = log_returns_weights.loc[indices_train]\n",
    "\n",
    "        # Обучение модели с весами\n",
    "        model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "        model.fit(X_train, y_train, sample_weight=weights_train)\n",
    "\n",
    "        # Последние данные для предсказания\n",
    "        latest_data = X.iloc[[-1]]\n",
    "\n",
    "        # Прогноз на horizon дней вперед\n",
    "        future_predictions = []\n",
    "        for day in range(horizon):\n",
    "            predicted_price = model.predict(latest_data)[0]\n",
    "            future_predictions.append(predicted_price)\n",
    "\n",
    "            # Обновляем данные для следующего прогноза\n",
    "            new_row = latest_data.to_numpy().flatten().tolist()[1:] + [predicted_price]\n",
    "            columns = [f\"lag_{i}\" for i in range(1, n_lags + 1)]\n",
    "            latest_data = pd.DataFrame([new_row], columns=columns)\n",
    "\n",
    "        # Сохраняем прогнозы\n",
    "        predictions[ticker] = future_predictions\n",
    "\n",
    "elif config[\"model\"] == \"Prophet\":\n",
    "    for ticker in price_data.columns:\n",
    "        # Подготовка исходных данных\n",
    "        df = price_data[ticker].copy().reset_index()  # Преобразуем индекс в столбец\n",
    "        df = df.rename(columns={\"index\": \"Date\", ticker: \"y\"}).dropna()  # Переименовываем столбцы\n",
    "\n",
    "        # Присоединяем веса\n",
    "        df[\"weight\"] = df[\"Date\"].map(log_returns_weights).fillna(1.0)\n",
    "\n",
    "        if len(df) < 100:\n",
    "            print(f\"Недостаточно данных для {ticker}, пропускаем.\")\n",
    "            continue\n",
    "\n",
    "        # Эмуляция sample_weight: дублируем строки согласно весу (с округлением)\n",
    "        df[\"dup_count\"] = (df[\"weight\"] * 10).round().astype(int).clip(lower=1)\n",
    "        df_weighted = df.loc[df.index.repeat(df[\"dup_count\"])][[\"Date\", \"y\"]]\n",
    "\n",
    "        # Обучение модели\n",
    "        model = Prophet()\n",
    "        model.fit(df_weighted.rename(columns={\"Date\": \"ds\"}))  # Prophet ожидает столбец 'ds' для дат\n",
    "\n",
    "        # Прогноз\n",
    "        future = model.make_future_dataframe(periods=horizon)\n",
    "        forecast = model.predict(future)\n",
    "\n",
    "        # Сохраняем прогноз\n",
    "        predicted_values = forecast[[\"ds\", \"yhat\"]].tail(horizon)[\"yhat\"].values\n",
    "        predictions[ticker] = predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем DataFrame с прогнозными ценами закрытия\n",
    "price_data_fcst = pd.DataFrame(predictions, index=pd.date_range(start=price_data.index[-1] + pd.Timedelta(days=1), periods=horizon))\n",
    "price_data_fcst.index.name = \"Date\"\n",
    "\n",
    "# Выводим DataFrame с прогнозами\n",
    "print(\"Прогнозные цены закрытия:\")\n",
    "print(price_data_fcst.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение исторических и прогнозных данных\n",
    "combined_data = pd.concat([price_data, price_data_fcst])\n",
    "\n",
    "# Нормализация объединенных данных\n",
    "normalized_combined_data = combined_data / combined_data.iloc[0]\n",
    "\n",
    "# Фильтрация данных, начиная с 2024 года\n",
    "normalized_combined_data = normalized_combined_data.loc[\"2024-01-01\":]\n",
    "\n",
    "# Визуализация нормализованных данных\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for ticker in normalized_combined_data.columns:\n",
    "    # Полная линия для каждого тикера\n",
    "    plt.plot(\n",
    "        normalized_combined_data.index, \n",
    "        normalized_combined_data[ticker], \n",
    "        label=ticker\n",
    "    )\n",
    "\n",
    "# Добавляем вертикальную линию для разделения истории и прогноза\n",
    "plt.axvline(x=price_data.index[-1], color=\"red\", linestyle=\"--\", label=\"Граница прогноза\")\n",
    "\n",
    "plt.title(\"Нормализованные исторические и прогнозные цены акций\")\n",
    "plt.xlabel(\"Дата\")\n",
    "plt.ylabel(\"Относительная цена\")\n",
    "plt.legend(title=\"Тикеры\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Блок с оптимизацией портфеля с учетом прогнозных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Рассчитываем логарифмическую доходность на основе объединенных данных\n",
    "log_returns_fcst = np.log(combined_data / combined_data.shift(1)).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим корреляционную матрицу доходностей\n",
    "correlation_matrix = log_returns_fcst.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Получим список тикеров из конфига\n",
    "tickers = config['tickers'] + config['bond_tickers']\n",
    "\n",
    "# 2. Оставим только нужные активы в log_returns\n",
    "log_returns_subset_fcst = log_returns_fcst[tickers]\n",
    "\n",
    "# 3. Создадим бенчмарк — среднюю доходность портфеля\n",
    "benchmark_returns_fcst = log_returns_subset_fcst.mean(axis=1)\n",
    "\n",
    "# 4. Расчёт бета-коэффициентов\n",
    "def compute_beta_fcst(returns_df_fcst, benchmark_returns_fcst):\n",
    "    betas_fcst = {}\n",
    "    for ticker in returns_df_fcst.columns:\n",
    "        model_fcst = LinearRegression()\n",
    "        model_fcst.fit(benchmark_returns_fcst.values.reshape(-1, 1), returns_df_fcst[ticker].values)\n",
    "        betas_fcst[ticker] = model_fcst.coef_[0]  # это и есть β\n",
    "    return pd.Series(betas_fcst)\n",
    "\n",
    "betas_series_fcst = compute_beta_fcst(log_returns_subset_fcst, benchmark_returns_fcst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Рассчитываем среднюю логарифмическую доходность и ковариационную матрицу\n",
    "mean_daily_returns_fcst = log_returns_fcst.mean()  # Средняя логарифмическая доходность по каждому тикеру\n",
    "cov_matrix_fcst = log_returns_fcst.cov()  # Ковариационная матрица логарифмических доходностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Оптимизация портфеля через коэффициент Шарпа\n",
    "def neg_sharpe_ratio_fcst(weights, expected_log_returns_fcst, cov_matrix_fcst, risk_free_rate):\n",
    "    port_return_fcst = np.dot(weights, expected_log_returns_fcst)\n",
    "    port_volatility_fcst = np.sqrt(np.dot(weights.T, np.dot(cov_matrix_fcst, weights)))\n",
    "    sharpe_ratio_fcst = (port_return_fcst - risk_free_rate / 252) / port_volatility_fcst  # Отрицательный Шарп для минимизации\n",
    "    return -sharpe_ratio_fcst  # Отрицательный коэффициент Шарпа для максимизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Ограничения и условия\n",
    "constraints_fcst = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1})  # сумма весов = 1\n",
    "bounds_fcst = tuple((0, 1) for _ in range(num_assets))  # веса от 0.1 до 1\n",
    "initial_guess_fcst = num_assets * [1. / num_assets]  # равные веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимизация\n",
    "opt_result_fcst = minimize(\n",
    "    neg_sharpe_ratio_fcst, # отрицательный коэфф Шарпа\n",
    "    initial_guess_fcst, # равные веса активов\n",
    "    args=(mean_daily_returns_fcst, cov_matrix_fcst, config[\"risk_free_rate\"]), # аргументы для целевой функции где мы отрицательный коэф Шарпа искали\n",
    "    method=\"SLSQP\", # метод минимизации \n",
    "    bounds=bounds, # ограничения по весам активов\n",
    "    constraints=constraints # ограничение по сумме весов\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимальные веса\n",
    "optimal_weights_fcst = opt_result_fcst.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оптимальная дневная доходность и риск\n",
    "port_return_daily_fcst = np.dot(optimal_weights_fcst, mean_daily_returns_fcst)\n",
    "port_volatility_daily_fcst = np.sqrt(np.dot(optimal_weights_fcst.T, np.dot(cov_matrix_fcst, optimal_weights_fcst)))\n",
    "\n",
    "# Годовые метрики\n",
    "port_return_annual_fcst = port_return_daily_fcst * 252\n",
    "port_volatility_annual_fcst = port_volatility_daily_fcst * np.sqrt(252)\n",
    "\n",
    "# Шарп\n",
    "sharpe_ratio_annual_fcst = (port_return_annual_fcst - config[\"risk_free_rate\"]) / port_volatility_annual_fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Печатаем метрики\n",
    "print(\"Оптимальные веса в портфеле:\")\n",
    "for ticker, weight in zip(tickers, optimal_weights_fcst):\n",
    "    print(f\"{ticker}: {weight:.2%}\")\n",
    "\n",
    "print(f\"\\nДоходность портфеля: {port_return_daily_fcst:.4f} в день, {port_return_annual_fcst:.2%} в год\")\n",
    "print(f\"Риск портфеля (волатильность): {port_volatility_daily_fcst:.4f} в день, {port_volatility_annual_fcst:.2%} в год\")\n",
    "print(f\"Коэффициент Шарпа (годовой): {sharpe_ratio_annual_fcst:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Исключаем активы с нулевым весом\n",
    "non_zero_weights_fcst = [(ticker, weight) for ticker, weight in zip(tickers, optimal_weights_fcst) if weight > 1e-6]  # Убираем веса, близкие к нулю\n",
    "\n",
    "# Проверяем, есть ли активы с ненулевыми весами\n",
    "if non_zero_weights_fcst:\n",
    "    # Разделяем тикеры и веса\n",
    "    filtered_tickers_fcst, filtered_weights_fcst = zip(*non_zero_weights_fcst)\n",
    "\n",
    "    # Построение диаграммы\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(filtered_weights_fcst, labels=filtered_tickers_fcst, autopct=\"%1.1f%%\", startangle=140)\n",
    "    plt.title(\"Оптимальное распределение активов\")\n",
    "    plt.axis(\"equal\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Все активы имеют нулевые веса. Нечего отображать.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Доходность портфеля с равными и оптимальными весами\n",
    "equal_weights_fcst = np.repeat(1/num_assets, num_assets)\n",
    "\n",
    "# Капитал под управлением\n",
    "initial_capital = 100\n",
    "\n",
    "# Кумулятивная доходность\n",
    "portfolio_equal_fcst = (log_returns_fcst @ equal_weights_fcst).cumsum()\n",
    "portfolio_optimal_fcst = (log_returns_fcst @ optimal_weights_fcst).cumsum()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(portfolio_equal_fcst, label=\"Равные веса\", linestyle=\"--\")\n",
    "plt.plot(portfolio_optimal_fcst, label=\"Оптимальный портфель\", linewidth=2)\n",
    "plt.title(\"Кумулятивная доходность портфеля\")\n",
    "plt.ylabel(\"Суммарная лог-доходность\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
